{
    "system_architecture": {
        "name": "Local RAG (Retrieval-Augmented Generation)",
        "description": "A fully local RAG pipeline using Supabase for vector storage and Ollama for inference.",
        "version": "1.0.0",
        "last_updated": "2026-02-19"
    },
    "ingestion_pipeline": {
        "source_types": [
            "PDF Documents",
            "YouTube Links"
        ],
        "processing_steps": [
            {
                "step": "Text Extraction",
                "tool": "pdf-parse",
                "version": "1.1.1",
                "handling": "Extracts raw text from PDF buffer"
            },
            {
                "step": "Chunking",
                "strategy": "Fixed Token/Character Window",
                "parameters": {
                    "chunk_size": 500,
                    "chunk_overlap": 50,
                    "splitting_rules": [
                        "Period + Space",
                        "Newline"
                    ]
                }
            },
            {
                "step": "Embedding Generation",
                "model": "nomic-embed-text",
                "provider": "Ollama (Local)",
                "dimensions": 768,
                "api_endpoint": "/api/embeddings"
            },
            {
                "step": "Vector Storage",
                "database": "Supabase (PostgreSQL 15+)",
                "extension": "pgvector",
                "table": "Vector_chunk",
                "schema": {
                    "resource_id": "UUID (Foreign Key to Resources)",
                    "content_embeddings": "vector(768)",
                    "text": "text",
                    "chunk_index": "integer"
                }
            }
        ]
    },
    "retrieval_pipeline": {
        "method": "Cosine Similarity",
        "function_name": "match_chunks",
        "index_type": "ivfflat (vector_cosine_ops)",
        "parameters": {
            "match_count": 20,
            "filter_by": [
                "subject_id",
                "resource_ids (optional)"
            ]
        },
        "query_processing": {
            "embedding_model": "nomic-embed-text",
            "dimensions": 768
        }
    },
    "generation_pipeline": {
        "model": {
            "name": "deepseek-r1:8b",
            "provider": "Ollama (Local)",
            "parameters": {
                "temperature": 0.3,
                "top_p": 0.9,
                "num_predict": 4096,
                "stream": true
            }
        },
        "prompt_structure": {
            "system_prompt": [
                "You are an AI Study Buddy â€” a knowledgeable, friendly, and precise tutor.",
                "RULES:",
                "1. Base your answers PRIMARILY on the provided context.",
                "2. Always cite which document your information comes from.",
                "3. Supplement with general knowledge only if necessary.",
                "4. Prioritize document content over general facts if contradictory.",
                "5. Be concise but thorough.",
                "6. Admit ignorance if answer is not in context.",
                "7. Use headings for topics.",
                "8. Note that 'Units' in syllabus are equivalent to 'Chapters'."
            ],
            "context_injection": {
                "format": "RELEVANT CONTEXT FROM STUDENT'S DOCUMENTS:\n---\n[Document: {title}]\n{chunk_text}\n---",
                "fallback": "No relevant context found in the student's documents."
            },
            "history_injection": {
                "format": "PREVIOUS CONVERSATION:\nStudent: {msg}\nAI Tutor: {msg}",
                "limit": "Last 10 messages"
            }
        }
    },
    "frontend_integration": {
        "streaming_protocol": "Newline-delimited JSON (NDJSON)",
        "event_types": [
            {
                "type": "status",
                "payload": "Verifying access... -> Encoding... -> Searching... -> Thinking... -> Generating..."
            },
            {
                "type": "reasoning",
                "payload": "<think> token stream"
            },
            {
                "type": "token",
                "payload": "Response text token"
            },
            {
                "type": "done",
                "payload": "Citations array (Title, Excerpt, Similarity Score)"
            },
            {
                "type": "error",
                "payload": "Error message"
            }
        ],
        "citation_logic": "Deduplicated list of source documents used in context"
    }
}